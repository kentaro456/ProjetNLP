# üöÄ Guide de D√©marrage Rapide

**Projet**: Classification de Genres de Films (NLP)
**Auteur**: LUKAU
**Professeur**: Rakia JAZIRI

---

## ‚ö° D√©marrage en 5 Minutes

### √âtape 1: Installation des D√©pendances (2 min)

```bash
# Installer les packages Python
pip install -r requirements.txt

# T√©l√©charger les stopwords NLTK
python -c "import nltk; nltk.download('stopwords')"
```

### √âtape 2: Test de l'Installation (30 sec)

```bash
python test_installation.py
```

‚úÖ Si tous les tests passent, continuez √† l'√©tape 3.
‚ùå Si des tests √©chouent, suivez les instructions affich√©es.

### √âtape 3: Ex√©cution du Projet (5-10 min)

```bash
python main.py
```

**C'est tout!** Le pipeline va:
1. T√©l√©charger le dataset depuis Kaggle
2. Nettoyer et filtrer les donn√©es
3. Extraire les features TF-IDF
4. D√©tecter et supprimer les outliers
5. Visualiser avec PCA
6. Entra√Æner 3 mod√®les
7. √âvaluer avec les 5 m√©triques

---

## üìÅ O√π Trouver les R√©sultats?

Apr√®s ex√©cution, consultez le dossier `outputs/`:

### Graphiques
- `genre_distribution_filtered.png` - Distribution des 5 genres
- `outlier_detection.png` - Visualisation des outliers
- `pca_scatter_train.png` - PCA 2D du train set
- `pca_scatter_test.png` - PCA 2D du test set
- `metrics_comparison.png` - **Comparaison des 3 mod√®les**
- `confusion_matrix_best_model.png` - **Matrice de confusion**

### Rapports
- `metrics_results.csv` - **Tableau des 4 m√©triques**
- `classification_report_best_model.txt` - D√©tails par classe
- `outlier_report.txt` - Statistiques outliers
- `pipeline_*.log` - Log d'ex√©cution

---

## üéØ Les 5 M√©triques (IMPORTANT pour l'√©valuation)

Le fichier `outputs/metrics_results.csv` contient:

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Random Forest | 0.XX | 0.XX | 0.XX | 0.XX |
| SVM | 0.XX | 0.XX | 0.XX | 0.XX |
| Naive Bayes | 0.XX | 0.XX | 0.XX | 0.XX |

**5√®me m√©trique**: Matrice de Confusion dans `confusion_matrix_best_model.png`

---

## üìä Validation des Concepts du Cours

Apr√®s ex√©cution, v√©rifiez que vous avez:

### ‚úÖ Isolation Forest (Slide 155)
- `outputs/outlier_detection.png` - Visualisation
- `outputs/outlier_report.txt` - Statistiques

### ‚úÖ PCA (Slide 129)
- `outputs/pca_scatter_train.png` - Train set
- `outputs/pca_scatter_test.png` - Test set
- `outputs/pca_variance_explained.png` - Variance

### ‚úÖ Random Forest (M√©thodes Ensemble)
- `models/random_forest.pkl` - Mod√®le sauvegard√©
- Dans `metrics_results.csv` - Performance

### ‚úÖ Les 5 M√©triques
- `metrics_results.csv` - 4 m√©triques num√©riques
- `confusion_matrix_best_model.png` - 5√®me m√©trique

---

## üîß Personnalisation (Optionnel)

### Changer le nombre de genres
√âditez `main.py`, ligne ~97:
```python
top_genres = preprocessing.get_top_n_genres(df, n=5)  # Changez 5 par 3 ou 7
```

### Changer le taux d'outliers
√âditez `main.py`, ligne ~125:
```python
outlier_mask = outlier_detection.detect_outliers_isolation_forest(
    X_train_tfidf, contamination=0.1  # Changez 0.1 par 0.05 ou 0.15
)
```

### Changer le nombre de features TF-IDF
√âditez `main.py`, ligne ~113:
```python
X_train_tfidf, X_test_tfidf, vectorizer = features.create_tfidf_features(
    X_train, X_test, max_features=5000  # Changez 5000 par 3000 ou 10000
)
```

---

## üêõ Probl√®mes Fr√©quents

### "ModuleNotFoundError: No module named 'kagglehub'"
```bash
pip install kagglehub
```

### "LookupError: NLTK stopwords not found"
```bash
python -c "import nltk; nltk.download('stopwords')"
```

### "MemoryError" pendant l'ex√©cution
R√©duisez `max_features` √† 3000 dans `main.py`

### T√©l√©chargement Kaggle lent
C'est normal, le dataset fait ~15 MB. Patience!

---

## üìö Structure des Fichiers Source

Pour comprendre le code:

1. **`src/preprocessing.py`** - T√©l√©chargement et nettoyage
2. **`src/features.py`** - TF-IDF et train/test split
3. **`src/outlier_detection.py`** - Isolation Forest ‚≠ê
4. **`src/visualization.py`** - PCA ‚≠ê
5. **`src/models.py`** - 3 classifiers (dont Random Forest ‚≠ê)
6. **`src/evaluation.py`** - Les 5 m√©triques ‚≠ê
7. **`main.py`** - Orchestrateur

‚≠ê = Concepts du cours valid√©s

---

## üìù Pour la Pr√©sentation

Points cl√©s √† mentionner:

### 1. Rigueur Acad√©mique
- Train/Test split **AVANT** tout processing
- Outliers d√©tect√©s sur **train uniquement**
- Pas de data leakage

### 2. Les 3 Concepts Valid√©s
- **Isolation Forest** (Slide 155): 10% outliers supprim√©s
- **PCA** (Slide 129): Visualisation 2D de 5000 features
- **Random Forest**: M√©thode ensemble performante

### 3. Les 5 M√©triques
- **Accuracy**: Score global
- **Precision** (weighted): G√®re d√©s√©quilibre
- **Recall** (weighted): Capacit√© d√©tection
- **F1-Score** (weighted): √âquilibre P/R
- **Matrice de Confusion**: D√©tails par classe

### 4. R√©sultats
- Comparez les 3 mod√®les dans `metrics_comparison.png`
- Analysez la matrice de confusion
- Identifiez le meilleur mod√®le (F1-Score)

---

## ‚úÖ Checklist Avant Soumission

- [ ] `python test_installation.py` r√©ussit
- [ ] `python main.py` s'ex√©cute sans erreur
- [ ] Dossier `outputs/` contient 13+ fichiers
- [ ] Dossier `models/` contient 3 fichiers .pkl
- [ ] `metrics_results.csv` a 3 lignes (3 mod√®les)
- [ ] `confusion_matrix_best_model.png` est lisible
- [ ] Le meilleur mod√®le est identifi√©

---

## üéì Crit√®res d'√âvaluation (Auto-V√©rification)

### Structure Professionnelle ‚úÖ
- [x] Code modulaire (7 fichiers .py s√©par√©s)
- [x] Pas de Jupyter Notebook
- [x] Architecture claire (src/, data/, outputs/, models/)

### Concepts du Cours ‚úÖ
- [x] Isolation Forest (Slide 155) - Code dans `outlier_detection.py`
- [x] PCA (Slide 129) - Code dans `visualization.py`
- [x] Random Forest - Code dans `models.py`

### Les 5 M√©triques ‚úÖ
- [x] Accuracy - Calcul√©e dans `evaluation.py`
- [x] Precision (weighted) - Calcul√©e dans `evaluation.py`
- [x] Recall (weighted) - Calcul√©e dans `evaluation.py`
- [x] F1-Score (weighted) - Calcul√©e dans `evaluation.py`
- [x] Matrice de Confusion - G√©n√©r√©e dans `evaluation.py`

### Rigueur Acad√©mique ‚úÖ
- [x] Train/Test split stratifi√©
- [x] Pr√©vention data leakage
- [x] Reproductibilit√© (random_state=42)
- [x] Gestion d√©s√©quilibre (class_weight='balanced')

### Documentation ‚úÖ
- [x] Code comment√© en fran√ßais
- [x] R√©f√©rences aux slides du cours
- [x] README.md complet
- [x] Logs d'ex√©cution

---

## üèÜ Objectif Final

**D√©montrer la ma√Ætrise des 3 concepts cl√©s:**

1. ‚úÖ D√©tection d'Anomalies (Isolation Forest)
2. ‚úÖ R√©duction de Dimension (PCA)
3. ‚úÖ M√©thodes Ensemblistes (Random Forest)

**Avec une √©valuation rigoureuse:**

- ‚úÖ Les 5 m√©triques calcul√©es et compar√©es
- ‚úÖ Approche acad√©mique sans data leakage
- ‚úÖ R√©sultats reproductibles

---

**Bonne chance! üöÄ**

Pour toute question, consultez:
- `README.md` - Documentation compl√®te
- `outputs/pipeline_*.log` - D√©tails d'ex√©cution
- Le code source dans `src/` - Commentaires d√©taill√©s
