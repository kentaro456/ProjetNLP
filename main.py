#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PROJET NLP: Classification de Genres de Films

Pipeline principal du projet:
1. T√©l√©chargement et preprocessing du dataset
2. Extraction de features (TF-IDF)
3. D√©tection d'outliers (Isolation Forest)
4. R√©duction de dimension (PCA)
5. Entra√Ænement de mod√®les (NB, SVM, RF)
6. √âvaluation compl√®te
"""

import sys
import logging
import time
from pathlib import Path
from datetime import datetime

# Ajouter le dossier src au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent / 'src'))

# Imports des modules du projet
from src import preprocessing, features, outlier_detection, visualization, models, evaluation


def setup_logging():
    """Configure le syst√®me de logging pour le pipeline"""
    # Cr√©er le dossier outputs si n√©cessaire
    Path("outputs").mkdir(parents=True, exist_ok=True)

    # Configuration du logging
    log_filename = f"outputs/pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )

    return logging.getLogger(__name__)


def create_directories():
    """Cr√©e l'arborescence compl√®te du projet"""
    dirs = [
        'data/raw',
        'data/processed',
        'outputs',
        'models',
        'src'
    ]

    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)

    print("‚úì Arborescence du projet cr√©√©e")


def print_header(title: str, char: str = "="):
    """Affiche un en-t√™te format√©"""
    width = 70
    print("\n" + char * width)
    print(title.center(width))
    print(char * width)


def main():
    """
    Pipeline principal du projet NLP

    Ex√©cute s√©quentiellement toutes les √©tapes du projet
    avec gestion des erreurs et logging d√©taill√©.
    """
    # D√©marrer le chronom√®tre
    start_time = time.time()

    # Configuration du logging
    logger = setup_logging()

    # En-t√™te du projet
    print_header("PROJET NLP - CLASSIFICATION DE GENRES DE FILMS", "=")
    print("Auteur: LUKAU")
    print("Professeur: Rakia JAZIRI")
    print("Master 1 Big Data")
    print(f"Date: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print_header("", "=")

    try:
        # ================================================================
        # √âTAPE 0: SETUP
        # ================================================================
        print_header("√âTAPE 0/7: INITIALISATION", "-")
        create_directories()
        logger.info("Projet initialis√© avec succ√®s")

        # ================================================================
        # √âTAPE 1: T√âL√âCHARGEMENT ET PREPROCESSING
        # ================================================================
        print_header("√âTAPE 1/7: T√âL√âCHARGEMENT ET PREPROCESSING", "-")
        logger.info("D√©but du t√©l√©chargement du dataset...")

        # T√©l√©charger le dataset
        dataset_path = preprocessing.download_dataset()
        logger.info(f"Dataset t√©l√©charg√©: {dataset_path}")

        # Explorer le dataset
        df = preprocessing.load_and_explore_data(dataset_path)
        logger.info(f"Dataset charg√©: {len(df):,} √©chantillons")

        # Identifier les top 5 genres
        top_genres = preprocessing.get_top_n_genres(df, n=5)
        logger.info(f"Top 5 genres s√©lectionn√©s: {top_genres}")

        # Nettoyer et filtrer
        df_clean = preprocessing.preprocess_dataset(df, top_genres)
        logger.info(f"Dataset nettoy√©: {len(df_clean):,} √©chantillons")

        # Sauvegarder
        preprocessing.save_processed_data(df_clean, 'data/processed/cleaned_data.csv')
        logger.info("Dataset nettoy√© sauvegard√©")

        # ================================================================
        # √âTAPE 2: EXTRACTION DE FEATURES
        # ================================================================
        print_header("√âTAPE 2/7: EXTRACTION DE FEATURES (TF-IDF)", "-")
        logger.info("D√©but de l'extraction de features...")

        # S√©parer X et y
        X = df_clean['Plot']
        y = df_clean['Genre']

        # Train/Test Split stratifi√© (80/20)
        X_train, X_test, y_train, y_test = features.split_data(X, y, test_size=0.2, random_state=42)
        logger.info(f"Split: {len(X_train):,} train / {len(X_test):,} test")

        # Vectorisation TF-IDF (fit sur train uniquement)
        X_train_tfidf, X_test_tfidf, vectorizer = features.create_tfidf_features(
            X_train, X_test, max_features=5000, ngram_range=(1, 2)
        )
        logger.info(f"TF-IDF: {X_train_tfidf.shape[1]:,} features")

        # ================================================================
        # √âTAPE 3: D√âTECTION D'OUTLIERS (TRAIN ONLY)
        # ================================================================
        print_header("√âTAPE 3/7: D√âTECTION D'OUTLIERS (Isolation Forest - Slide 155)", "-")
        logger.info("D√©but de la d√©tection d'outliers (TRAIN SET uniquement)...")

        # D√©tecter les outliers avec Isolation Forest
        outlier_mask = outlier_detection.detect_outliers_isolation_forest(
            X_train_tfidf, contamination=0.1, random_state=42
        )

        # Supprimer les outliers du train set
        X_train_clean, y_train_clean = outlier_detection.remove_outliers(
            X_train_tfidf, y_train, outlier_mask
        )
        logger.info(f"Outliers supprim√©s: {len(y_train) - len(y_train_clean):,}")

        # Visualiser les outliers
        outlier_detection.visualize_outliers(
            X_train_tfidf, outlier_mask, 'outputs/outlier_detection.png'
        )

        # Rapport sur les outliers
        outlier_detection.save_outlier_report(
            outlier_mask, y_train, 'outputs/outlier_report.txt'
        )
        logger.info("D√©tection d'outliers termin√©e")

        # ================================================================
        # √âTAPE 4: VISUALISATION (PCA)
        # ================================================================
        print_header("√âTAPE 4/7: VISUALISATION (PCA 2D - Slide 129)", "-")
        logger.info("D√©but de la r√©duction dimensionnelle avec PCA...")

        # Convertir sparse matrices en dense pour PCA
        X_train_dense = X_train_clean.toarray()
        X_test_dense = X_test_tfidf.toarray()

        # Appliquer PCA (2 composantes)
        X_train_pca, X_test_pca, pca_model, var_ratio = visualization.apply_pca(
            X_train_dense, X_test_dense, n_components=2, random_state=42
        )
        logger.info(f"PCA: Variance expliqu√©e = {sum(var_ratio)*100:.2f}%")

        # Cr√©er toutes les visualisations
        visualization.create_all_visualizations(
            X_train_pca, X_test_pca, y_train_clean, y_test, pca_model, var_ratio
        )
        logger.info("Visualisations PCA g√©n√©r√©es")

        # ================================================================
        # √âTAPE 5: ENTRA√éNEMENT DES MOD√àLES
        # ================================================================
        print_header("√âTAPE 5/7: ENTRA√éNEMENT DES MOD√àLES (3 Classifiers)", "-")
        logger.info("D√©but de l'entra√Ænement des mod√®les...")

        # Entra√Æner les 3 mod√®les
        all_models = models.train_all_models(X_train_clean, y_train_clean)
        logger.info(f"Mod√®les entra√Æn√©s: {list(all_models.keys())}")

        # ================================================================
        # √âTAPE 6: √âVALUATION (LES 5 M√âTRIQUES)
        # ================================================================
        print_header("√âTAPE 6/7: √âVALUATION (LES 5 M√âTRIQUES)", "-")
        logger.info("D√©but de l'√©valuation sur le test set...")

        # √âvaluation compl√®te avec les 5 m√©triques
        results_df = evaluation.evaluate_and_save_all(
            all_models, X_test_tfidf, y_test, top_genres
        )
        logger.info("√âvaluation compl√®te termin√©e")

        # ================================================================
        # √âTAPE 7: R√âSUM√â FINAL
        # ================================================================
        print_header("√âTAPE 7/7: R√âSUM√â FINAL", "-")

        # Temps d'ex√©cution
        elapsed_time = time.time() - start_time
        minutes = int(elapsed_time // 60)
        seconds = int(elapsed_time % 60)

        print(f"\n‚úì PIPELINE TERMIN√â AVEC SUCC√àS")
        print(f"\nTemps d'ex√©cution: {minutes} min {seconds} sec")

        print("\n" + "="*70)
        print("R√âSULTATS FINAUX")
        print("="*70)

        # Afficher le tableau des r√©sultats
        print("\nPerformances des Mod√®les:")
        print(results_df.to_string(index=False))

        # Meilleur mod√®le
        best_model = results_df.iloc[0]['Model']
        best_f1 = results_df.iloc[0]['F1-Score']
        print(f"\nüèÜ Meilleur mod√®le: {best_model} (F1-Score: {best_f1*100:.2f}%)")

        print("\n" + "="*70)
        print("FICHIERS G√âN√âR√âS")
        print("="*70)

        print("\nüìä DONN√âES:")
        print("  - data/raw/dataset.csv - Dataset original Kaggle")
        print("  - data/processed/cleaned_data.csv - Dataset nettoy√© (5 genres)")

        print("\nüìà GRAPHIQUES:")
        print("  - outputs/genre_distribution_original.png - Distribution tous genres")
        print("  - outputs/genre_distribution_filtered.png - Distribution 5 genres")
        print("  - outputs/outlier_detection.png - Visualisation outliers")
        print("  - outputs/pca_scatter_train.png - PCA train set")
        print("  - outputs/pca_scatter_test.png - PCA test set")
        print("  - outputs/pca_variance_explained.png - Variance PCA")
        print("  - outputs/metrics_comparison.png - Comparaison mod√®les")
        print("  - outputs/confusion_matrix_best_model.png - Matrice confusion")

        print("\nüìã RAPPORTS:")
        print("  - outputs/metrics_results.csv - Tableau comparatif")
        print("  - outputs/tfidf_features.csv - Top features TF-IDF")
        print("  - outputs/outlier_report.txt - Rapport outliers")
        print("  - outputs/classification_report_best_model.txt - Rapport d√©taill√©")
        print(f"  - {Path('outputs').glob('pipeline_*.log').__next__()} - Log pipeline")

        print("\nü§ñ MOD√àLES:")
        print("  - models/naive_bayes.pkl - Mod√®le Naive Bayes")
        print("  - models/svm.pkl - Mod√®le SVM")
        print("  - models/random_forest.pkl - Mod√®le Random Forest")

        print("\n" + "="*70)
        print("VALIDATION P√âDAGOGIQUE")
        print("="*70)

        print("\n‚úÖ CONCEPTS DU COURS VALID√âS:")
        print("  1. ‚úì D√©tection d'Anomalies: Isolation Forest (Slide 155)")
        print("  2. ‚úì R√©duction de Dimension: PCA (Slide 129)")
        print("  3. ‚úì M√©thodes Ensemblistes: Random Forest")
        print("  4. ‚úì Les 5 M√©triques: Accuracy, Precision, Recall, F1, Confusion Matrix")

        print("\n‚úÖ RIGUEUR ACAD√âMIQUE:")
        print("  - Train/Test split stratifi√© (80/20)")
        print("  - TF-IDF fitt√© sur train uniquement")
        print("  - Outliers d√©tect√©s sur train uniquement")
        print("  - PCA fitt√© sur train uniquement")
        print("  - √âvaluation sur test set uniquement")
        print("  - Reproductibilit√©: random_state=42")

        print("\n" + "="*70)
        logger.info("Pipeline termin√© avec succ√®s")

    except Exception as e:
        logger.error(f"ERREUR CRITIQUE: {str(e)}", exc_info=True)
        print(f"\n‚ùå ERREUR: {str(e)}")
        print("Consultez le fichier log pour plus de d√©tails")
        sys.exit(1)


if __name__ == "__main__":
    main()
